<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.4.0 for Hugo" />
  

  
  










  







  
  

  
  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Learning on Graphs Conference Team" />

  
  
  
    
  
  <meta name="description" content="" />

  
  <link rel="alternate" hreflang="en-us" href="https://logconference.github.io/schedule-orals/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
      
      
        
      
    
    
    

    
    
    
      
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.d7dd5dd48663428d4a57541f2b83866b.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu189fa68429203f426dcffc0b3b1a2f13_39239_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu189fa68429203f426dcffc0b3b1a2f13_39239_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://logconference.github.io/schedule-orals/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
    <meta property="twitter:site" content="@logconference" />
    <meta property="twitter:creator" content="@logconference" />
  
  <meta property="og:site_name" content="Learning on Graphs Conference" />
  <meta property="og:url" content="https://logconference.github.io/schedule-orals/" />
  <meta property="og:title" content="Learning on Graphs Conference" />
  <meta property="og:description" content="" /><meta property="og:image" content="https://logconference.github.io/media/logo_hud0fe5dab583aaa056b8094d898ea0f3c_37272_300x300_fit_lanczos_3.png" />
    <meta property="twitter:image" content="https://logconference.github.io/media/logo_hud0fe5dab583aaa056b8094d898ea0f3c_37272_300x300_fit_lanczos_3.png" /><meta property="og:locale" content="en-us" />
  
    
    
  

  



  

  

  





  <title>Learning on Graphs Conference</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper   " data-wc-page-id="95489b1c3fe31ccb55cf71912bf795b2" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.d5094052a6270c81ab9495f4173f87a9.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    











  


<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"><img src="/media/logo_hud0fe5dab583aaa056b8094d898ea0f3c_37272_0x70_resize_lanczos_3.png" alt="Learning on Graphs Conference"
            
            ></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"><img src="/media/logo_hud0fe5dab583aaa056b8094d898ea0f3c_37272_0x70_resize_lanczos_3.png" alt="Learning on Graphs Conference"
          
          ></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#hero"><span>Home</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Calls</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/cfp"><span>Call for Papers</span></a>
              
                <a class="dropdown-item" href="/call-for-tutorials"><span>Call for Tutorials</span></a>
              
                <a class="dropdown-item" href="/sponsors"><span>Call for Sponsors</span></a>
              
                <a class="dropdown-item" href="/call-for-reviewers"><span>Call for Reviewers</span></a>
              
                <a class="dropdown-item" href="/call-for-meetups"><span>Call for Local Meetups</span></a>
              
            </div>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Program</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/conference-program"><span>Conference Program</span></a>
              
                <a class="dropdown-item" href="/schedule-keynotes"><span>Keynote</span></a>
              
                <a class="dropdown-item" href="/schedule-orals"><span>Orals</span></a>
              
                <a class="dropdown-item" href="/schedule-posters"><span>Poster Session</span></a>
              
            </div>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Attend</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/register"><span>Register</span></a>
              
                <a class="dropdown-item" href="/venue"><span>Venue</span></a>
              
                <a class="dropdown-item" href="/accommodation"><span>Accommodation</span></a>
              
            </div>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#pcs"><span>Organizers</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#sponsors"><span>Sponsors</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Pages</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/conduct"><span>Code of Conduct</span></a>
              
                <a class="dropdown-item" href="/dei"><span>DEI Statement</span></a>
              
                <a class="dropdown-item" href="/reviews"><span>Reviewer Guidelines</span></a>
              
            </div>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Past</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="http://log2022.logconference.org"><span>LoG 2022</span></a>
              
                <a class="dropdown-item" href="http://log2023.logconference.org"><span>LoG 2023</span></a>
              
                <a class="dropdown-item" href="http://log2024.logconference.org"><span>LoG 2024</span></a>
              
            </div>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  
  

  

  

  
  
  
  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="orals" class="home-section wg-blank  "  >
   <div class="home-section-bg " >
     
   </div>
    <div class="container">

    
      <div class="row  justify-content-center">
      
        
          <div class="section-heading col-12 mb-3 text-center">
            <h1 class="mb-0">Oral Presentations</h1>
            <p class="mt-1">Learning on Graphs Conference, 2025</p>
          </div>
        
      
    

      



  <div class="col-12">
    <figure><center>
  <img src="logo_conf_below_512_512.png" width="30%"/>
  <figcaption></figcaption>
</center></figure> 
<center>
<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vRmnO0AoPlhEFwtj_dAw5VuFrNiYTSwAzdfZJsNohOLhRrKY8gpQWi0D2TvJ3W0Pg/pubhtml?gid=87443520&amp;single=false&amp;widget=true&amp;headers=false" style="border: 0" width="100%" height="700" scrolling="no"></iframe>
</center>
<hr>
<details class="toc-inpage d-print-none  " open>
  <summary class="font-weight-bold">Table of Contents</summary>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#virtual-nodes-go-temporal">Virtual Nodes Go Temporal</a></li>
    <li><a href="#efficient-neural-common-neighbor-for-temporal-graph-link-prediction">Efficient Neural Common Neighbor for Temporal Graph Link Prediction</a></li>
    <li><a href="#generalized-degrees-for-scalable-discrete-time-dynamic-graph-generation">Generalized Degrees for Scalable Discrete Time Dynamic Graph Generation</a></li>
    <li><a href="#tango-graph-neural-dynamics-via-learned-energy-and-tangential-flows">TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows</a></li>
    <li><a href="#short-range-oversquashing">Short-Range Oversquashing</a></li>
    <li><a href="#learning-kronecker-structured-graphs-from-smooth-signals">Learning Kronecker-Structured Graphs from Smooth Signals</a></li>
    <li><a href="#less-is-more-using-buffer-nodes-to-reduce-excessive-majority-node-influence-in-class-imbalance-graphs">Less is More: Using Buffer Nodes to Reduce Excessive Majority Node Influence in Class Imbalance Graphs</a></li>
    <li><a href="#cross-domain-graph-anomaly-detection-via-test-time-training-with-homophily-guided-self-supervision">Cross-Domain Graph Anomaly Detection via Test-Time Training with Homophily-Guided Self-Supervision</a></li>
    <li><a href="#differentiable-community-detection-with-graph-neural-networks-and-stochastic-block-models">Differentiable Community Detection with Graph Neural Networks and Stochastic Block Models</a></li>
    <li><a href="#exploring-intrinsic-structures-of-hyperedges-as-point-clouds">Exploring Intrinsic Structures of Hyperedges as Point Clouds</a></li>
    <li><a href="#one-model-any-conjunctive-query-graph-neural-networks-for-answering-queries-over-incomplete-knowledge-graphs">One Model, Any Conjunctive Query: Graph Neural Networks for Answering Queries over Incomplete Knowledge Graphs</a></li>
    <li><a href="#gl-equivariant-metanetworks-for-learning-on-low-rank-weight-spaces">GL Equivariant Metanetworks for Learning on Low Rank Weight Spaces</a></li>
    <li><a href="#position-beyond-euclidean--foundation-models-should-embrace-non-euclidean-geometries">Position: Beyond Euclidean – Foundation Models Should Embrace Non-Euclidean Geometries</a></li>
  </ul>
</nav>
</details>

<h2 id="virtual-nodes-go-temporal">Virtual Nodes Go Temporal</h2>
<p><strong>Authors:</strong> Sofiane ENNADIR, Yassir Jedra, Oleg Smirnov, Lele Cao</p>
<p><strong>Date:</strong> December 10, 2025</p>
<p><strong>Time slot:</strong> 9:30-9:50 (MST)</p>
<p><strong>Abstract:</strong>
Learning representations of temporally evolving graphs, also known as Continuous-Time Dynamic Graphs (CTDGs), has gained considerable attention due to their ability to model a wide range of real-world phenomena. Recent efforts extend the well-established message-passing paradigm and Graph Neural Network (GNN) models, originally designed for static graphs, to account for the temporal dimension of dynamic graphs. Although these methods have shown promising results, they often inherit limitations from their static counterparts, particularly regarding the capture of long-range interactions. In static settings, adding Virtual Nodes (VNs) has proven effective in overcoming locality constraints and boosting performance. In this work, we conduct a theoretical analysis of the impact of VNs in CTDG-based models. Specifically, we introduce the concept of information flow, which examines how information propagates through a graph following an event. From this perspective, we highlight inherent limitations of existing CTDG-based approaches and demonstrate how adding VNs can address these constraints. Building on these insights, we propose k-TVNs, a framework that incorporates a set of fully connected VNs, each representing a distinct community within the graph. Through both theoretical investigation and empirical validation, we show that incorporating VNs substantially improves the performance of CTDG models.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=jdKtkiH9ze" target="_blank" rel="noopener">https://openreview.net/forum?id=jdKtkiH9ze</a></p>
<hr>
<h2 id="efficient-neural-common-neighbor-for-temporal-graph-link-prediction">Efficient Neural Common Neighbor for Temporal Graph Link Prediction</h2>
<p><strong>Authors:</strong> Xiaohui Zhang, Yanbo Wang, Xiyuan Wang, Muhan Zhang</p>
<p><strong>Date:</strong> December 10, 2025</p>
<p><strong>Time slot:</strong> 9:50-10:10 (MST)</p>
<p><strong>Abstract:</strong> Temporal graphs are widespread in real-world applications such as social networks, as well as trade and transportation networks. Predicting dynamic links within these evolving graphs is a key problem. Many memory-based methods use temporal interaction histories to generate node embeddings, which are then combined to predict links. However, these approaches primarily focus on individual node representations, often overlooking the inherently pairwise nature of link prediction. While some recent methods attempt to capture pairwise features, they tend to be limited by high computational complexity arising from repeated embedding calculations, making them unsuitable for large-scale datasets like the Temporal Graph Benchmark (TGB). To address the critical need for models that combine strong expressive power with high computational efficiency for link prediction on large temporal graphs, we propose Temporal Neural Common Neighbor (TNCN). Our model achieves this balance by adapting the powerful pairwise modeling principles of Neural Common Neighbor (NCN) to an efficient temporal architecture. TNCN improves upon NCN by efficiently preserving and updating temporal neighbor dictionaries for each node and by using multi-hop common neighbors to learn more expressive pairwise representations. TNCN achieves new state-of-the-art performance on Review from five large-scale real-world TGB datasets, 6 out of 7 datasets in the transductive setting and 3 out of 7 in the inductive setting on small- to medium-scale datasets. Additionally, TNCN demonstrates excellent scalability, outperforming prominent GNN baselines by up to 30.3 times in speed on large datasets. Our code is available at \href{https://github.com/GraphPKU/TNCN}{https://github.com/GraphPKU/TNCN}.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=ffsDVGiKRm" target="_blank" rel="noopener">https://openreview.net/forum?id=ffsDVGiKRm</a></p>
<h2 id="generalized-degrees-for-scalable-discrete-time-dynamic-graph-generation">Generalized Degrees for Scalable Discrete Time Dynamic Graph Generation</h2>
<p><strong>Authors:</strong> Kjartan van Driel, Leonardo Niccolò Ialongo, Pablo Andrés Astudillo, Stefan Thurner</p>
<p><strong>Date:</strong> December 10, 2025</p>
<p><strong>Time slot:</strong> 10:10-10:30 (MST)</p>
<p><strong>Abstract:</strong> The evolution of many real-world systems is best described by dynamic graphs, whose statistical properties reflect the constraints of the system. When forecasting their dynamics, the goal is to generate a time series of graphs respecting these underlying constraints. Existing scalable dynamic graph learning methods, however, are designed for local tasks such as link prediction or node classification, and their independent, local predictions are ill-suited for graph generation. This limitation is particularly relevant for discrete time dynamic graphs, where coarse time resolution induces dependencies among edges within each snapshot. We propose using a generalized notion of degrees to model such dependencies directly, thereby shifting the focus from individual links to node dynamics. This approach bypasses the need to learn a sparse graph representation, and yields an inductive representation that enables the generation of large-scale discrete-time dynamic graphs.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=yVJXsCC8NY" target="_blank" rel="noopener">https://openreview.net/forum?id=yVJXsCC8NY</a></p>
<h2 id="tango-graph-neural-dynamics-via-learned-energy-and-tangential-flows">TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows</h2>
<p><strong>Authors:</strong> Moshe Eliasof, Eldad Haber, Carola-Bibiane Schönlieb</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 9:00-9:20 (MST)</p>
<p><strong>Abstract:</strong> We introduce TANGO, a dynamical-systems framework for graph representation learning that steers node features via a learned energy landscape. At its core is a learnable Lyapunov function whose gradient defines an energy-decreasing direction, guaranteeing stability and convergence. To preserve flexibility, we add a learned tangential message-passing component that evolves features along energy level sets. This orthogonal decomposition—gradient descent plus tangential evolution—enables effective signal propagation even in flat or ill-conditioned regions common in graph learning, mitigates oversquashing, and remains compatible with diverse GNN backbones. Empirically, TANGO achieves strong performance across node and graph classification and regression benchmarks, validating jointly learned energy functions and tangential flows.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=c3aN3wecSt" target="_blank" rel="noopener">https://openreview.net/forum?id=c3aN3wecSt</a></p>
<h2 id="short-range-oversquashing">Short-Range Oversquashing</h2>
<p><strong>Authors:</strong> Yaaqov Mishayev, Yonatan Sverdlov, Tal Amir, Nadav Dym</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 9:20-9:40 (MST)</p>
<p><strong>Abstract:</strong> Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.</p>
<p>In this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.</p>
<p>We further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=rmX8Jamnyg" target="_blank" rel="noopener">https://openreview.net/forum?id=rmX8Jamnyg</a></p>
<h2 id="learning-kronecker-structured-graphs-from-smooth-signals">Learning Kronecker-Structured Graphs from Smooth Signals</h2>
<p><strong>Authors:</strong> Changhao Shi, Gal Mishne</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 9:40-10:00 (MST)</p>
<p><strong>Abstract:</strong> Graph learning, or network inference, is a prominent problem in graph signal processing (GSP). GSP generalizes the Fourier transform to non-Euclidean domains, and graph learning is pivotal to applying GSP when these domains are not known. With the recent prevalence of multi-way data, there has been growing interest in product graphs that naturally factorize dependencies across different ways. However, the types of graph products that can be learned are still limited for modeling diverse dependency structures. In this paper, we study the problem of learning a Kronecker-structured product graph from smooth signals. Unlike the more commonly used Cartesian product, the Kronecker product models dependencies in a more intricate, non-separable way, but posits harder constraints on the graph learning problem. To tackle this non-convex problem, we propose an alternating scheme to optimize each factor graph in turn and provide theoretical guarantees for its asymptotic convergence. We also modify the proposed algorithm to learn graphs of the strong product, a denser graph product that covers the Kronecker product. We conduct experiments on synthetic and real-world graphs and demonstrate our approach&rsquo;s efficacy and superior performance compared to existing methods.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=kuDtgSMEFn" target="_blank" rel="noopener">https://openreview.net/forum?id=kuDtgSMEFn</a></p>
<h2 id="less-is-more-using-buffer-nodes-to-reduce-excessive-majority-node-influence-in-class-imbalance-graphs">Less is More: Using Buffer Nodes to Reduce Excessive Majority Node Influence in Class Imbalance Graphs</h2>
<p><strong>Authors:</strong> Less is More: Using Buffer Nodes to Reduce Excessive Majority Node Influence in Class Imbalance Graphs</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 14:30-14:50 (MST)</p>
<p><strong>Abstract:</strong> Graph Neural Networks (GNNs), despite success in node classification, struggle with class-imbalanced graphs, leading to minority node misclassification. Existing methods that synthesize minority nodes often overlook how majority nodes propagate misleading information through majority-minority edges; our analysis confirms this negative impact. To address this, we propose BufferGraph, a framework that inserts buffer nodes on such edges. These nodes act as controlled bottlenecks to reduce excessive majority node influence. And we theoretically demonstrate they reduce minority node feature distortion. Experiments on five real-world datasets show BufferGraph improves accuracy by up to 2% over state-of-the-art methods, excelling in imbalanced settings and for minority classes with high heterophily. Code is available at \url{https://github.com/Persdre/BufferGraph}.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=6ikB5L1kzq" target="_blank" rel="noopener">https://openreview.net/forum?id=6ikB5L1kzq</a></p>
<h2 id="cross-domain-graph-anomaly-detection-via-test-time-training-with-homophily-guided-self-supervision">Cross-Domain Graph Anomaly Detection via Test-Time Training with Homophily-Guided Self-Supervision</h2>
<p><strong>Authors:</strong> Delaram Pirhayatifard, Arlei Silva</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 14:50-15:10 (MST)</p>
<p><strong>Abstract:</strong> Abstract: Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present GADT3, a novel test-time training framework for cross-domain GAD. GADT3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that GADT3 significantly outperforms existing approaches, achieving average improvements of over 8.2% in AUROC and AUPRC compared to the best competing model.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=sB3LqdOlNb" target="_blank" rel="noopener">https://openreview.net/forum?id=sB3LqdOlNb</a></p>
<h2 id="differentiable-community-detection-with-graph-neural-networks-and-stochastic-block-models">Differentiable Community Detection with Graph Neural Networks and Stochastic Block Models</h2>
<p><strong>Authors:</strong> William Arliss, W. Graham Mueller</p>
<p><strong>Date:</strong> December 11, 2025</p>
<p><strong>Time slot:</strong> 15:10-15:30 (MST)</p>
<p><strong>Abstract:</strong> We propose a set of loss functions adapted from Stochastic Block Model (SBM) likelihood functions to train Graph Neural Networks (GNNs) for the task of unsupervised community detection. Identifying latent community structures is a prominent challenge for many graph applications. SBMs are classical models that describe the generating process of random graphs and are commonly used to infer community structure. The likelihood functions associated with SBMs are well-defined, differentiable, and measure the quality of inferred community partitions; this makes them particularly useful for unsupervised learning with GNNs. Our proposed loss functions are independent of any specific GNN architecture and demonstrate competitive or improved community detection performance against several alternatives. Evaluation is carried out on multiple architectures and datasets, offering a thorough empirical analysis of the state of community detection with GNNs.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=T1vdfm1THf" target="_blank" rel="noopener">https://openreview.net/forum?id=T1vdfm1THf</a></p>
<h2 id="exploring-intrinsic-structures-of-hyperedges-as-point-clouds">Exploring Intrinsic Structures of Hyperedges as Point Clouds</h2>
<p><strong>Authors:</strong> Lige Zhang, Dongmian Zou</p>
<p><strong>Date:</strong> December 12, 2025</p>
<p><strong>Time slot:</strong> 14:30-14:50 (MST)</p>
<p><strong>Abstract:</strong> Hypergraph neural networks (HNNs) provide a powerful framework for modeling high-order relationships in complex data. However, existing approaches often overlook the intrinsic patterns carried by hyperedges. Some methods simplify a hyperedge as a fully connected subgraph or treat it as an intermediate node-like entity, which limits the expressivity of the resulting models and neglects the potentially rich information of hyperedges. In this work, we offer a new perspective for hypergraph modeling by modeling a hyperedge as a point cloud with learnable features. Building on this view, we present a novel Hypergraph Kernel Network (HypKN) framework for hypergraph representation learning, which fully exploits the intrinsic hypergraph structure. The core component in HypKN is a Kernel Attention Message Passing (KAMP) module, which mimics the classical convolution operation defined for non-Euclidean data structures and enjoys provable stability results. We evaluate HypKN on ten real-world and synthetic hypergraph datasets for node classification, where it consistently outperforms classical HNN baselines and achieves state-of-the-art performance on several benchmarks.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=CIYl0o3d5d" target="_blank" rel="noopener">https://openreview.net/forum?id=CIYl0o3d5d</a></p>
<h2 id="one-model-any-conjunctive-query-graph-neural-networks-for-answering-queries-over-incomplete-knowledge-graphs">One Model, Any Conjunctive Query: Graph Neural Networks for Answering Queries over Incomplete Knowledge Graphs</h2>
<p><strong>Authors:</strong> Krzysztof Olejniczak, Xingyue Huang, Mikhail Galkin, Ismail Ilkan Ceylan</p>
<p><strong>Date:</strong> December 12, 2025</p>
<p><strong>Time slot:</strong> 14:50-15:10 (MST)</p>
<p><strong>Abstract:</strong> Motivated by the incompleteness of modern knowledge graphs, a new setup for query answering has emerged, where the goal is to predict answers that do not necessarily appear in the knowledge graph, but are present in its completion. In this paper, we formally introduce and study two query answering problems, namely, query answer classification and query answer retrieval. To solve these problems, we propose ANYCQ, a model that can classify answers to any conjunctive query on any knowledge graph. At the core of our framework lies a graph neural network trained using a reinforcement learning objective to answer Boolean queries. Trained only on simple, small instances, ANYCQ generalizes to large queries of arbitrary structure, reliably classifying and retrieving answers to queries that existing approaches fail to handle. This is empirically validated through our newly proposed, challenging benchmarks. Finally, we empirically show that ANYCQ can effectively transfer to completely novel knowledge graphs when equipped with an appropriate link prediction model, highlighting its potential for querying incomplete data.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=Fo2GLDelI1" target="_blank" rel="noopener">https://openreview.net/forum?id=Fo2GLDelI1</a></p>
<h2 id="gl-equivariant-metanetworks-for-learning-on-low-rank-weight-spaces">GL Equivariant Metanetworks for Learning on Low Rank Weight Spaces</h2>
<p><strong>Authors:</strong> Theo Putterman, Derek Lim, Yoav Gelberg, Michael M. Bronstein, Stefanie Jegelka, Haggai Maron</p>
<p><strong>Date:</strong> December 12, 2025</p>
<p><strong>Time slot:</strong> 15:10-15:30 (MST)</p>
<p><strong>Abstract:</strong> Low-rank adaptations (LoRAs) have revolutionized the finetuning of large foundation models, enabling efficient adaptation even with limited computational resources. The resulting proliferation of LoRAs together with the recent advances of weight-space learning present exciting opportunities for applying machine learning techniques that take these low-rank weights themselves as inputs. In this paper, we investigate the potential of Learning on LoRAs (LoL), a setup where machine learning models learn and make predictions on datasets of LoRA weights. Motivated by previous weight-space learning works, we first identify the inherent parameter symmetries of our data &ndash; low-rank decompositions of weights &ndash; which differ significantly from the parameter symmetries of standard neural networks. To efficiently process LoRA weights, we develop several symmetry-aware invariant or equivariant LoL models. In diverse experiments, we show that our LoL architectures can process LoRA weights to predict CLIP scores, finetuning data attributes, finetuning data membership, and accuracy on downstream tasks. We also show that LoL models trained on LoRAs of one pretrained model can effectively generalize to LoRAs trained on other models from the same model family. As an example of the utility of LoL, our LoL models can accurately estimate CLIP scores of diffusion models and ARC-C test accuracy of LLMs over 50,000 times faster than standard evaluation. As part of this work, we finetuned and will release datasets of more than ten thousand text-to-image diffusion-model and language-model LoRAs.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=fHRRYBZAmS" target="_blank" rel="noopener">https://openreview.net/forum?id=fHRRYBZAmS</a></p>
<h2 id="position-beyond-euclidean--foundation-models-should-embrace-non-euclidean-geometries">Position: Beyond Euclidean – Foundation Models Should Embrace Non-Euclidean Geometries</h2>
<p><strong>Authors:</strong> Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Irwin King, Menglin Yang, Melanie Weber, Rex Ying</p>
<p><strong>Date:</strong> December 12, 2025</p>
<p><strong>Time slot:</strong> 15:30-15:50 (MST)</p>
<p><strong>Abstract:</strong> In the era of foundation models and Large Language Models (LLMs), Euclidean space has been the de facto geometric setting for machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. At a large scale, real-world data often exhibits inherently non-Euclidean structures, such as multi-way relationships, hierarchies, symmetries, and non-isotropic scaling, in a variety of domains, such as languages, vision, and the natural sciences. It is challenging to effectively capture these structures within the constraints of Euclidean spaces. This position paper argues that moving beyond Euclidean geometry is not merely an optional enhancement but a necessity to maintain the scaling law for the next-generation of foundation models. By adopting these geometries, foundation models could more efficiently leverage the aforementioned structures. Task-aware adaptability that dynamically reconfigures embeddings to match the geometry of downstream applications could further enhance efficiency and expressivity. Our position is supported by a series of theoretical and empirical investigations of prevalent foundation models. Finally, we outline a roadmap for integrating non-Euclidean geometries into foundation models, including strategies for building geometric foundation models via fine-tuning, training from scratch, and hybrid approaches.</p>
<p><strong>OpenReview:</strong> <a href="https://openreview.net/forum?id=WoK4o90lln" target="_blank" rel="noopener">https://openreview.net/forum?id=WoK4o90lln</a></p>

  </div>



    
      </div>
    

    </div>
  </section>


  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © 2025 Learning on Graphs Conference.
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.3d946de2e8784a477845261d87025092.js"></script>

    
    
    
      
      
        <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
      

      
      

      

      

    

    
    
    
      <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js" type="module"></script>
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.1e6778f7ffd0c664a75c7abec9c8025d.js"></script>

    
    
      <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>
    
    
    
    






</body>
</html>
